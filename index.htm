<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>KAMoulox - Online unmixing of large historical archives</title>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" type="text/css" href="css/bulma.css">
  <link rel="stylesheet" type="text/css" href="css/hero.css">
</head>
<body>
  <section class="hero is-primary is-large header-image">
    <div class="hero-head">
      <header class="nav">
        <div class="container">
          <div class="nav-left">
            <a class="nav-item" href="index.htm">
              KAMoulox Project
            </a>
          </div>
          <span class="nav-toggle">
            <span></span>
            <span></span>
            <span></span>
          </span>
          <div class="nav-right nav-menu">
            <a href="publications.html" class="nav-item">
              Publications
            </a>
            <a href="software.html" class="nav-item">
              Software
            </a>
            <a href="partners.html" class="nav-item">
              Partners
            </a>
            <span class="nav-item">
              <a href="http://archives.crem-cnrs.fr/" class="button is-info">
                <span>CREM Archive</span>
              </a>
            </span>
          </div>
        </div>
      </header>
    </div>
    <div class="hero-body">
      <div class="container has-text-centered">
        <h1 class="title is-2">
          KAMoulox
        </h1>
        <h2 class="subtitle is-5">
          Online unmixing of large historical archives
        </h2>
      </div>
    </div>
  </section>
  <div class="section main">
    <div class="content">
      <h2 id="starting-point-archives-of-the-cnrs---musée-de-lhomme">Starting point: archives of the CNRS - Musée de l’Homme</h2>
      <ul>
      <li>French ethnologists to record world audio heritage</li>
      <li>Since 1900: 42k documents, 32k digitized</li>
      <li>From 199 countries, 1200 ethnies <img src="figures/crem-map.png" alt="" style="background-color ;" width="100%"></li>
      </ul>
      <h2 id="valorization-potential">Valorization potential</h2>
      <ul>
      <li>High scientific value: 2600 scientists/month</li>
      <li>Repurposing possibilities: musical creation, licensing, etc.</li>
      </ul>
      <h2 id="challenges">Challenges</h2>
      <iframe width="350" height="150" style="float:right" frameborder="0" scrolling="no" marginheight="0" marginwidth="0" src="http://archives.crem-cnrs.fr/archives/items/CNRSMH_I_1900_001_002/player/350x50">
      </iframe>
      <ul>
      <li>Most recordings are <strong>old, degraded, noisy</strong></li>
      <li>Users are <strong>not</strong> sound engineers</li>
      <li>Impossible to automatically restore <strong>all</strong> entries</li>
      </ul>
      <h2 id="key-final-objectives">Key final objectives</h2>
      <ul>
      <li>Audio restoration for the non expert</li>
      <li>Embed online audio restoration tools <em>in the archives</em></li>
      <li>Create <strong>useful</strong> tools for digital humanities</li>
      </ul>
      <h2 id="identified-risks">Identified risks</h2>
      <ul>
      <li>Scientists users have their own research objectives</li>
      <li>CREM is heavily solicited by signal processing researchers</li>
      <li>For them: no useful feedback so far</li>
      </ul>
      <div class="solutions">
      <pre><code>&lt;ul&gt;
          &lt;li&gt;Focus on a few usecases defined __with the users__&lt;/li&gt;
          &lt;li&gt;Exploit users&#39; data for training systems&lt;/li&gt;
      &lt;/ul&gt;</code></pre>
      </div>
      <h2 id="usecases-defined-with-the-users">Usecases defined <em>with the users</em></h2>
      <p><img src="figures/photos/clara.jpg" alt="" style="background-color ; float:right" height="200em"> * Prestation by <strong>Clara Biermann</strong> - Ethnomusicolgist, CREM archives specialist - July to september 2016: 10k€ on KAMoulox - Organize collaboration with CREM reserchers * <strong>Report</strong> on the use-cases desired by users - Denoising: wind and support noise removal - Separation: percussion, lead/choir separation * <strong>Datasets</strong> train/test for each, at least 1h30 per category</p>
      <h2 id="future-milestones">Future milestones</h2>
      <ul>
      <li>Training systems with user data</li>
      <li>User-centered design
      <ul>
      <li>One online tool per usecase</li>
      <li>Involve users in the design: release early &amp; often</li>
      </ul></li>
      <li>Meet the target scientific audience: dedicated conferences
      <ul>
      <li>Scientific collaborations on digital humanities grounds</li>
      </ul></li>
      </ul>
      <h2 id="starting-point-audio-processing-expertise">Starting point: audio processing expertise</h2>
      <ul>
      <li>Audio source separation theory and implementations</li>
      <li>Probabilistic modeling for time series</li>
      <li>Recent breakthroughs: KAM and fast separation
      <div class="references">
      <ul>
      <li>
      A. Liutkus et al. “Gaussian processes for underdetermined source separation.” IEEE TSP, 59.7 (2011): 3155-3167.
      </li>
      <li>
      A. Liutkus et al. “Kernel additive models for source separation.” IEEE TSP, 62.16 (2014): 4298-4310.
      </li>
      <li>
      A. Liutkus et al. “Generalized Wiener filtering with fractional power spectrograms.” IEEE ICASSP, 2015
      </li>
      </ul>
      </div></li>
      </ul>
      <h2 id="valorization-potential-1">Valorization potential</h2>
      <ul>
      <li>Promising leading research on non Gaussian models</li>
      <li>Bringing cutting edge audio effects to users</li>
      </ul>
      <h2 id="challenges-1">Challenges</h2>
      <ul>
      <li>Non-tractable <span class="math inline"><em>α</em></span>-stable likelihoods, difficult inference</li>
      <li>Learning sources models as kernels</li>
      <li>Human-in-the-loop at the model level</li>
      </ul>
      <h2 id="key-final-objectives-1">Key final objectives</h2>
      <ul>
      <li>Robustness: filtering in noise, robust inference</li>
      <li>Explaining heuristics with the <span class="math inline"><em>α</em></span>-stable paradigm</li>
      <li>Flexible and exemplar-based trainable audio models</li>
      </ul>
      <h2 id="beyond-the-gaussian-process-risks">Beyond the Gaussian process: risks</h2>
      <ol type="1">
      <li>Practical advantage of the <span class="math inline"><em>α</em></span>-stable model</li>
      </ol>
      <ul>
      <li>The need for convincing applications</li>
      <li>Going away from maximum likelihood</li>
      </ul>
      <ol start="2" type="1">
      <li>Computational load compatible with objectives of project</li>
      </ol>
      <ul>
      <li>MCMC is too slow yet for online processing</li>
      <li>Delicate <span class="math inline"><em>α</em></span>-stable multichannel generalization
      <div class="solutions">
      <ul>
      <li>
      Good models for noise signals and enhancement
      </li>
      <li>
      Scalable learning through sketching
      </li>
      <li>
      Hybrid <span class="math inline"><em>α</em></span>-stable/Gaussian models
      </li>
      </ul></li>
      </ul>
      </div>
      <h2 id="beyond-the-gaussian-process-achievements">Beyond the Gaussian process: achievements</h2>
      <ul>
      <li>Ph.D by Mathieu Fontaine (05/2016)
      <ul>
      <li>Co-funding from Région Lorraine</li>
      <li><strong>Publications</strong> 4 conferences, 1 journal in preparation</li>
      </ul></li>
      <li>Effective denoising algorithms
      <div class="references">
      <ul>
      <li>
      U. Simsekli et al. “Alpha-stable low-rank plus residual decomposition for speech enhancement.” ICASSP, 2018.
      </li>
      <li>
      M. Fontaine et al. “Explaining the parameterized wiener filter with alpha-stable processes.”IEEE WASPAA, 2017.
      </li>
      </ul></li>
      </ul>
      </div>
      <ul>
      <li>Moment-matching inference
      <div class="references">
      <ul>
      <li>
      M. Fontaine et al. “Scalable source localization with multichannel α-stable distributions.” EUSIPCO, 2017.
      </li>
      </ul></li>
      </ul>
      </div>
      <ul>
      <li>New hybrid probabilistic audio models
      <div class="references">
      <ul>
      <li>
      P. Magron et al. “Separation of nonnegative alpha-stable sources.” IEEE SPL, 2016.
      </li>
      <li>
      A. Liutkus et al. “Audio source separation with magnitude priors: the BEADS model.” IEEE ICASSP, 2018.
      </li>
      </ul>
      </div></li>
      </ul>
      <h2 id="nonparametric-models-for-audio-risks">Nonparametric models for audio: risks</h2>
      <ol type="1">
      <li>Kernel models outperformed by deep neural networks - Rapid breakthroughs demonstrate the superiority of DNN - Continue state-of-the-art research</li>
      <li>Scale up to archives volumes - Data-wise - User-wise</li>
      </ol>
      <div class="solutions">
      <pre><code>&lt;ul&gt;
        &lt;li&gt;Extensive benchmark of separation systems&lt;/li&gt;
        &lt;li&gt;DNN methods for data-driven&lt;/li&gt;
        &lt;li&gt;Kernel methods for user-driven&lt;/li&gt;
      &lt;/ul&gt;</code></pre>
      </div>
      <p>## Nonparametric models for audio: achievements * Postdoc by Fabian-Robert Stöter (12/2017) - Benchmarking - SiSEC campaign (2 LVA/ICA) - TASLP overview (AQ) - DNN-based separation</p>
      <div class="references" style="margin-bottom: 1em">
      <pre><code>&lt;ul&gt;
        &lt;li&gt;A. Liutkus et al. &quot;The 2016 signal separation evaluation campaign.&quot; LVA-ICA, 2017.&lt;/li&gt;
        &lt;li&gt;A. Nugraha et al. &quot;Multichannel music separation with deep neural networks.&quot; EUSIPCO, 2016&lt;/li&gt;
        &lt;li&gt;F. Stöter et al. &quot;Common fate model for unison source separation.&quot; IEEE ICASSP, 2016.&lt;/li&gt;
      &lt;/ul&gt;</code></pre>
      </div>
      <ul>
      <li><strong>Kernel models</strong> user-input, multichannel variants</li>
      </ul>
      <div class="references">
      <ul>
      <li>
      D. Fitzgerald et al. “Projection-based demixing of spatial audio.” IEEE/ACM TASLP, 24.9 (2016): 1556-1568.
      </li>
      <li>
      D. Fitzgerald et al. “User assisted separation of repeating patterns in time and frequency using magnitude projections.” IEEE ICASSP, 2017.
      </li>
      </ul>
      </div>
      <h2 id="overall-scientific-impact">Overall scientific impact</h2>
      <ul>
      <li>2 journals, 15 conferences</li>
      <li>150 citations of KAMoulox funded papers</li>
      <li>Invited talks: Kyoto Univ., Chicago Northwestern, Audiolabs Erlangen</li>
      </ul>
      <p><img src="figures/logos.jpg" alt="" style="background-color ; float:center" height="200em"></p>
      <h2 id="future-milestones-1">Future milestones</h2>
      <ul>
      <li>DNN-based audio separation
      <ul>
      <li>General-purpose open-source baseline</li>
      <li>Application to KAMoulox data</li>
      </ul></li>
      <li>From denoising to enhancement
      <ul>
      <li>DNN-based bandwidth extension, enhancement</li>
      </ul></li>
      <li><span class="math inline"><em>α</em></span>-stable formalism
      <ul>
      <li>Journal paper by M. Fontaine</li>
      <li>Large-scale learning through sketching</li>
      </ul></li>
      </ul>
      <h2 id="starting-point-telemeta">Starting point: Telemeta</h2>
      <ul>
      <li>Open-source Framework developped by Parisson since 2011</li>
      <li>Used by CREM for the <em>archives du CNRS - Musée de l’Homme</em></li>
      <li>Timeside: signal processing sub-system for Telemeta</li>
      </ul>
      <p><img src="figures/logos/telemeta.png" alt="" style="background-color ; float:center" height="70em"> <img src="figures/logos/crem.png" alt="" style="background-color ; float:center" height="70em"> <img src="figures/logos/parisson.png" alt="" style="background-color ; float:center" height="70em"></p>
      <div class="references">
      <ul>
      <li>
      T. Fillon. “Telemeta: An open-source web framework for ethnomusicological audio archives management and automatic analysis”. Intnl. Workshop on Digital Libraries for Musicology.
      </li>
      </ul>
      </div>
      <h2 id="challenges-2">Challenges</h2>
      <ul>
      <li>Extending Telemeta+Timeside for processing (not only information retrieval)</li>
      <li>Enabling user interaction</li>
      <li>Engineering challenge</li>
      </ul>
      <h2 id="key-final-objectives-2">Key final objectives</h2>
      <ul>
      <li>Embed KAMoulox algorithms in the real archives (Telemeta is mandatory)</li>
      <li>Bring recent audio restoration tools to digital humanities scientist</li>
      </ul>
      <h2 id="future-milestones-2">Future milestones</h2>
      <ul>
      <li>Client-side DNN processing (javascript)</li>
      <li>One online tool per usecase: denoising, separation</li>
      <li>Scientific outreach
      <ul>
      <li>Targetting digital humanities community</li>
      <li>Broad audience: youtube+interstices
      <p></li>
      </ul></li>
      </ul>
      <h1 id="final">Final</h1>
      <p><em>Cutting-edge signal processing research for the audio heritage</em></p>
      <ol type="1">
      <li><strong>Restoration of immaterial audio heritage</strong> denoising, declipping, enhancement</li>
      <li><strong>Online tools</strong> for scientists in digital humanities</li>
      </ol>
      <h3 id="challenges-3">Challenges</h3>
      <ul>
      <li><strong>Scale and noise</strong>: <span class="math inline">30000</span> precious but old, noisy and bandpass-limited items</li>
      <li><strong>Users</strong>: are scientists, but <strong>non experts</strong></li>
      </ul>
      <h3 id="investigations">Investigations</h3>
      <ul>
      <li><strong>Probabilistic models</strong>: <span class="math inline"><em>α</em></span>-stable distributions, multichannel filtering, robust regression, parameters estimation</li>
      <li><strong>Machine learning</strong>: deep neural networks, scalability, online processing</li>
      <li><strong>Community service</strong>: open data &amp; software, open-access online tools</li>
      </ul>
    </div>
  </div>
  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <p>
          The source code is licensed
          <a href="http://opensource.org/licenses/mit-license.php">MIT</a>. The website content
          is licensed <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC ANS 4.0</a>.
        </p>
        <p>
          <a class="icon" href="https://github.com/anr-kamoulox/website">
            <i class="fa fa-github"></i>
          </a>
        </p>
      </div>
    </div>
  </footer>
  <script async type="text/javascript" src="js/bulma.js"></script>
</body>
</html>
